# -*- coding: utf-8 -*-
#### Galaxy Classification Project ####

# Contributed by: Sankalpa Chowdhury & Sayan Hazra  

"""All_in_one.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1w0iYLnvZV1Q7gm1KhmAeOImobsRIJonQ
"""

# module file, containing all the modules
from modules import *
# data loading 
import data_storing as ds
# data segmentation
import data_segmentation as seg
# images visualization
import images_visualization as iv
# data augmentation
import data_augmentation as da
# image datagenerator
import image_generator as ig
# CNN model
import CNN_model as cnn
# model compilation
import model_compilation_training as mct
from tensorflow.keras.optimizers import Adam 
# model evaluation and visualization
import model_evaluation_visualization as mv
# intermediate activation
import intermediate_activation_vis as iav


# loading the data to the environment and creating the dataframe
print('Loading data---\n')
source = '/content/drive/My Drive/Astronomical /Galaxy_classification_project/images_training_rev1.zip'
destination = '/content/'
# unzipping to load the data
ds.unzipping(source, destination)
# creating the dataframe
csv_file = '/content/drive/My Drive/Astronomical /Galaxy_classification_project/training_solutions_rev1.csv'
label_df = ds.label_dataframe(csv_file)

# data segmentation based on different galaxy labels
print('\nData segmentation--\n')
# returns galaxy_ids, galaxy_names
g_id, g_names = seg.dataframe_segregator(label_df)
# source path of images unzipped
source_path = '/content/images_training_rev1'
# destination path of segmented images
dest_path = '/content/data'
seg.data_seg(source_path, dest_path, g_id, g_names)
print('\nSegmented raw image samples---\n')
folders = ['train', 'validation']
data_path = 'content/data'
galaxy_names = ['elliptical','lenticular','spiral']
iv.images_vis(folders, galaxy_names, data_path)

# Data augmentation
print('\nData augmentation---\n')
# train and validation directory source path
train_dir_src = '/content/data/train/'
validation_dir_src = '/content/data/validation/'
# train and validation directory destination path
train_dir_dest = '/content/Data1/Train/'
validation_dir_dest = '/content/Data1/Test/'
da.images_augment(train_dir_src, validation_dir_src, train_dir_dest, validation_dir_dest, g_id, g_names)
print('Image samples after augmentation')
folders = ['Train', 'Test']
data_path = 'content/Data1'
galaxy_names = ['elliptical','lenticular','spiral']
iv.images_vis(folders, galaxy_names, data_path)

print('\nImage_data_generator---\n')
train_dir = '/content/Data1/Train'
validation_dir = '/content/Data1/Test'
target = (150, 150) # target image size after Augmentation
batch_size = 32     # batch size (hyperparameter)
# class_mode
c_mode = 'categorical'
# returns train_generator, validation_generator
train_gen, val_gen = ig.image_generator_create(train_dir, validation_dir, target, batch_size, c_mode)

# model creation
print('Building CNN model---')
model = cnn.CNN_model_build()


# model compilation and training
# model compilation
print('Model compilation---')
loss_func = 'categorical_crossentropy'
# list of metrices to be shown durig a training
metrices = ['acc']
# function for optimiztion algorithm
optimizer_func = Adam(learning_rate=0.001)
mct.model_compile(model, optimizer_func, loss_func, metrices)
print('\nModel compilation done successfully!\n')
# threshold for validation_loss to be moitored by callbacks
print('\nDeclaring model callback objects---\n')
threshold_loss = 0.2300
# weights and bias files
model_param_file = 'best_model.h5'
# monitoring parameter for model_checkpoint
monitor_mc = 'val_accuracy'
# mode for model_checkpoint
mode_mc = 'max'
# custom callback, early_stopping, model_checkpoint objects are returned respectively
cs, est, mc = mct.model_callbacks(threshold_loss, model_param_file, monitor_mc, mode_mc)
# number of epochs
EPOCHS = 70
# train and validation generator
train_gen = train_gen
val_gen = val_gen
epoch_count = EPOCHS
# print('\nModel training---\n')
# storing the history of the model for further visualization 
history = mct.model_training(model, train_gen, val_gen, epoch_count, cs, est, mc)

# model evaluation
print('\nModel evaluation step---')
model_param_file = 'best_model.h5'
# val_gen = validation_generator
# train_gen = train_generator
mv.model_evaluation(model_param_file, train_gen, val_gen)
# model training performance visualization
mv.train_visualization(history)

# intermediate activation visualization
# image to be passed through the CNN  
img_path = '/content/Data1/Test/elliptical/elliptical_original_100867.jpg_41c4a759-6182-4aff-a2ea-535d232355a8.jpg'
# intermediate layers visualization
print('Visualization of intermediate acivations of model---\n')
iav.architecture_vis(img_path, model, 10)
